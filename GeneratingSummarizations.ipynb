{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import os\n",
    "import time\n",
    "import openai\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./config.ini']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"./config.ini\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_path)\n",
    "cohere_api_key = config.get('cohere', 'api_key')\n",
    "openai_api_key = config.get('openai', 'api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(\"\")\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"It's an exciting day for the development community. Cohere's state-of-the-art language AI is now available through Amazon SageMaker. This makes it easier for developers to deploy Cohere's pre-trained generation language model to Amazon SageMaker, an end-to-end machine learning (ML) service. Developers, data scientists, and business analysts use Amazon SageMaker to build, train, and deploy ML models quickly and easily using its fully managed infrastructure, tools, and workflows.\n",
    "At Cohere, the focus is on language. The company's mission is to enable developers and businesses to add language AI to their technology stack and build game-changing applications with it. Cohere helps developers and businesses automate a wide range of tasks, such as copywriting, named entity recognition, paraphrasing, text summarization, and classification. The company builds and continually improves its general-purpose large language models (LLMs), making them accessible via a simple-to-use platform. Companies can use the models out of the box or tailor them to their particular needs using their own custom data.\n",
    "Developers using SageMaker will have access to Cohere's Medium generation language model. The Medium generation model excels at tasks that require fast responses, such as question answering, copywriting, or paraphrasing. The Medium model is deployed in containers that enable low-latency inference on a diverse set of hardware accelerators available on AWS, providing different cost and performance advantages for SageMaker customers.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb Cell 4\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m co\u001b[39m.\u001b[39msummarize(text, model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msummarize-medium\u001b[39m\u001b[39m'\u001b[39m, length\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshort\u001b[39m\u001b[39m'\u001b[39m, extractiveness\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhigh\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "co.summarize(text, model='summarize-medium', length='short', extractiveness='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cohere's language AI on SageMaker.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_engine = \"gpt-3.5-turbo\"\n",
    "prompt = {\"role\":\"system\", \"content\":\"Categorize the following text using maximum five words: \" + text}\n",
    "response = openai.ChatCompletion.create(model = model_engine, messages = [prompt])[\"choices\"][0][\"message\"][\"content\"]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summarization(texts, model_engine = \"gpt-3.5-turbo\"):\n",
    "    main_text = \"Use a minimum of one word and a maximum of three words to describe the commonality between the following texts which are separated by the > symbol, shorter answers are preferred:\"\n",
    "    for text in texts:\n",
    "        main_text += \">\" + text\n",
    "    prompt = {\"role\":\"system\", \"content\": main_text}\n",
    "    return openai.ChatCompletion.create(model = model_engine, messages = [prompt])[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walkDir(path):\n",
    "    # recursively walk through dir to get all markdown files\n",
    "    # returns a dictionary where {filename1: content1, filename2: content2, ...}\n",
    "    summaries = {}\n",
    "    # only getting a subset of the directories and files because it's a lot\n",
    "    for item in os.listdir(path):\n",
    "        print(item)\n",
    "        content = os.path.join(path, item)\n",
    "        if os.path.isdir(content):\n",
    "            summaries.update(walkDir(content))\n",
    "        elif content.endswith(\".md\"):\n",
    "            fp = open(content)\n",
    "            not_done = True\n",
    "            while not_done:\n",
    "                try:\n",
    "                    summaries[item] = co.summarize(\"\".join(fp.readlines()), model='summarize-xlarge', length='short', extractiveness='high').summary\n",
    "                    not_done = False\n",
    "                except cohere.CohereAPIError:\n",
    "                    print(\"API limit reached trying again in 5 seconds\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "            fp.close()\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture.md\n",
      "Library as space separation.md\n",
      "Biophilic design.md\n",
      "Bridges.md\n"
     ]
    }
   ],
   "source": [
    "arch_path = \"/Users/kaanankharwa/Desktop/my-second-brain/Architecture\"\n",
    "arch_summarise = walkDir(arch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Architecture.md': 'Architecture is a field that entertain me. I like the way art (in the sens of beauty) and engineering is tied together to create such majestic structures and how ancient architecture is.',\n",
       " 'Library as space separation.md': 'A beautfiul yet simple way to combine space, beauty, and usability of a library is to use it as an ark to separate rooms from each other without having a plain separation. This is very elegant, especialy if filled with old and rare books.',\n",
       " 'Biophilic design.md': 'Biophilic design is a concept that is used in interior and building design to increase occupant connectivity to the natural environment through the use of direct and indirect nature, space, and place conditions.',\n",
       " 'Bridges.md': 'One documentary about the Pont Neuf in Paris just learned me some great things about architecture and challenged me and my thoughts about everyday things we use such as running water, sidewalk and bridges construction methods.'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch_summarise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented reality.md\n",
      "AR devices.md\n",
      "Mixed reality.md\n",
      "No-code tools for AR.md\n"
     ]
    }
   ],
   "source": [
    "ar_path = \"/Users/kaanankharwa/Desktop/my-second-brain/Augmented reality\"\n",
    "ar_summaries = walkDir(ar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecture and design.'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summarization(list(arch_summarise.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Augmented reality.md': \"Augmented reality (AR) is an interactive experience where real-world environment is augmented by virtual and computer-generated perceptual information. It is different than virtual reality (VR) where VR is a 100% computer-generated environment that you're evolving in.\",\n",
       " 'AR devices.md': 'There are four types of AR devices available so far : Heads up displays (HUD) Holographics displays Smart Glasses Handheld',\n",
       " 'Mixed reality.md': 'Mixed reality is in between the field of Augmented reality and Virtual reality, where the reality is mixed with computer-generated elements.',\n",
       " 'No-code tools for AR.md': \"For now I didn't tried any of these. Just bookmarked it and share it with my students for their projects.\"}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Immersive technology.'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summarization(list(ar_summaries.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Design and architecture.'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summarization(list(ar_summaries.values()) + list(arch_summarise.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walkDirSummary(path):\n",
    "    # recursively walk through dir to get all markdown files\n",
    "    # returns a dictionary where {filename1: content1, filename2: content2, ...}\n",
    "    summaries = {}\n",
    "    # only getting a subset of the directories and files because it's a lot\n",
    "    for item in os.listdir(path):\n",
    "        print(item)\n",
    "        content = os.path.join(path, item)\n",
    "        if os.path.isdir(content):\n",
    "            summaries.update(walkDir(content))\n",
    "        elif content.endswith(\".md\"):\n",
    "            fp = open(content)\n",
    "            not_done = True\n",
    "            while not_done:\n",
    "                try:\n",
    "                    text = co.summarize(\"\".join(fp.readlines()), model='summarize-xlarge', length='short', extractiveness='high').summary\n",
    "                    summaries[item] = generate_summarization([text])\n",
    "                    not_done = False\n",
    "                except cohere.CohereAPIError:\n",
    "                    print(\"API limit reached trying again in 5 seconds\")\n",
    "                    time.sleep(5)\n",
    "\n",
    "            fp.close()\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented reality.md\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb Cell 16\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ar_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/kaanankharwa/Desktop/my-second-brain/Augmented reality\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ar_word \u001b[39m=\u001b[39m walkDirSummary(ar_path)\n",
      "\u001b[1;32m/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     text \u001b[39m=\u001b[39m co\u001b[39m.\u001b[39msummarize(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(fp\u001b[39m.\u001b[39mreadlines()), model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msummarize-xlarge\u001b[39m\u001b[39m'\u001b[39m, length\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshort\u001b[39m\u001b[39m'\u001b[39m, extractiveness\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhigh\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39msummary\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     summaries[item] \u001b[39m=\u001b[39m generate_summarization([text])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     not_done \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mexcept\u001b[39;00m cohere\u001b[39m.\u001b[39mCohereAPIError:\n",
      "\u001b[1;32m/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb Cell 16\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     main_text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m text\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m prompt \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: main_text}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kaanankharwa/Desktop/GraphGurusVault/src/GeneratingSummarizations.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(model \u001b[39m=\u001b[39;49m model_engine, messages \u001b[39m=\u001b[39;49m [prompt])[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "ar_path = \"/Users/kaanankharwa/Desktop/my-second-brain/Augmented reality\"\n",
    "ar_word = walkDirSummary(ar_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
